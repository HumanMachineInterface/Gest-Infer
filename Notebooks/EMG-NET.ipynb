{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7f174414",
   "metadata": {},
   "source": [
    "This script includes the CNN based network to train, quantize and compile model used for EMG-based gesture classification. The EMG data was acquired using the 8-channel commercial Myo-Armband with a sampling frequency of 200Hz placed on the upper limb of the individual.\n",
    "\n",
    "Below are the steps.\n",
    "\n",
    "1. Importing and Pre-processing --> This step includes notching the input signal at 60Hz and windowig with overlap. Because the DPU engine require three channel input, the shape of the data is expanded to fit DPU requirement.\n",
    "\n",
    "2. Training --> After selecting the optimal hyperparamters,the architecture was defined and trained using tensorflow 2.* Therafter the accuracy of the model was visualized to confirm performance.\n",
    "\n",
    "3. Quantization --> Both Post-training (PTQ) and Quantization-aware training were implemented using Vitis-AI toolkit. The PTQ model was deployed to the Ultra96-V2. \n",
    "\n",
    "4. Compling --> The subgraph needed to be complied to produce .xmodel format and therafter to deployed to the Xilix FPGA (Ultra-96 v2) as an overlay in Pynq."
   ]
  },
  {
   "cell_type": "raw",
   "id": "98724107",
   "metadata": {},
   "source": [
    "STEP 1: IMPORTING AND PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df829fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import os\n",
    "\n",
    "from bmis_emg_utils import * \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e43368",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 12\n",
    "no_gesture = 7\n",
    "fs = 200\n",
    "\n",
    "notch_freq = 60.0\n",
    "quality_factor = 30.0\n",
    "fc = 10.0\n",
    "fh = 99.0\n",
    "order = 5\n",
    "window_time = 200\n",
    "overlap = 50\n",
    "no_channel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = get_data_subject_specific(subject, no_gesture, fs, notch_freq, quality_factor, fc, fh, order,\n",
    "                              window_time, overlap, no_channel)\n",
    "print('The total data shape is {} and label is {}'.format(data.shape, label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673375f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_time_domain_plot(data[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_time_domain_plot(data[1,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_list = ['LDG', 'MRDG', 'TFSG', 'PPG', 'PG', 'Cut', 'Rest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aceb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = spilt_data(data, label, ratio=0.1)\n",
    "print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f27b75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Expanding the input feature shape\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "print('Expanded Dimension are {}'.format(X_train.shape))\n",
    "input_size = X_train.shape[1:]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "        'Subject': [0],\n",
    "        'Validation_result':[0],\n",
    "        'Test_result_32_bit':[0],\n",
    "        'Test_result_8_bit_ptq':[0],\n",
    "        'Test_result_8_bit_qat':[0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a36080",
   "metadata": {},
   "source": [
    "STEP 2: TRAINING AND HYPER-PARMATER TUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47663076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emg_net():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=input_size)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(151, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"BMIS-EMG-NET\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668099cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = emg_net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f58302",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr, epsilon=1e-07, clipnorm=1)\n",
    "ls = 'sparse_categorical_crossentropy'\n",
    "mtr = 'accuracy'\n",
    "\n",
    "n_batches = 16\n",
    "n_epochs = 30\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "checkpoint_path = os.path.join('../checkpoint/full', str(subject))\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "     \n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                            filepath = checkpoint_path, save_best_only=True, monitor='accuracy', vebrose=1)\n",
    "\n",
    "num_folds = 3\n",
    "fold_no = 1\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "accuracy_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18959ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "    model = emg_net()\n",
    "    model.compile(optimizer=opt, loss=ls, metrics=mtr)\n",
    "    \n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} -------')\n",
    "    \n",
    "    history = model.fit(X_train[train], y_train[train], callbacks=[early_stop, checkpoint_callback],\n",
    "                        batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "    \n",
    "    scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold  {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    accuracy_per_fold.append(scores[1] *100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "          \n",
    "    fold_no = fold_no + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8f94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Average Score per fold \")\n",
    "\n",
    "for i in range(0, len(accuracy_per_fold)):\n",
    "    print('-----------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
    "print('-----------------------------------------------')\n",
    "print('Average Metrics for all folds: ')\n",
    "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result = np.mean(accuracy_per_fold)\n",
    "print(f'The three-fold cross validation result is: {validation_result}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_path = os.path.join(checkpoint_path, 'best_model')best_\n",
    "model = tf.keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uqt_test_loss, uqt_test_accuracy = model.evaluate(X_test, y_test)\n",
    "full_test_accuracy = uqt_test_accuracy * 100\n",
    "print(f'Accuracy of the Unquantized_model {full_test_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict, axis=-1)\n",
    "precision = precision_score(y_test, y_predict, average='weighted')\n",
    "recall = recall_score(y_test, y_predict, average='weighted')\n",
    "f1_score  = f1_score(y_test, y_predict, average='weighted')\n",
    "#f1_score = 2 * (sensitivity * specificity) / (sensitivity + specificity)\n",
    "\n",
    "print(f'Precision of the Unquantized_model {precision}')\n",
    "print(f'Recall of the  PTQ model {recall}')\n",
    "print(f'F1_score of the QAT model {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = '../full_models/EMG-NET-' + str(subject) + '.h5'\n",
    "model.save(saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa386436",
   "metadata": {},
   "source": [
    "STEP 3: POST TRAINING QUANTIZATION (Int-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958cab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_dataset = X_train[0:1000] # Note a minumum of 100 is needed and a maximum of 1000\n",
    "evaluation_dataset = X_test\n",
    "evaluation_dataset_gnd = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800219c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saved_float32_model = tf.keras.models.load_model(saved_model)\n",
    "ptq_quantizer = vitis_quantize.VitisQuantizer(saved_float32_model)\n",
    "ptq_quantized_model = ptq_quantizer.quantize_model(calib_dataset=calibration_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab87af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evalauting Post training quantization\n",
    "\n",
    "ptq_quantized_model.compile(loss=ls, metrics=mtr)\n",
    "ptq_loss, ptq_accuracy = ptq_quantized_model.evaluate(evaluation_dataset, evaluation_dataset_gnd)\n",
    "ptq_test_accuracy = ptq_accuracy * 100\n",
    "print(f'Post training quantization accuracy {ptq_test_accuracy}%')\n",
    "\n",
    "# Saving post training quantization\n",
    "quantized_model = '../ptq_models/ptq-EMG-NET-' + str(subject) + '.h5'\n",
    "ptq_quantized_model.save(quantized_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e288bb5",
   "metadata": {},
   "source": [
    "STEP 3.1: QUANTIZATION AWARE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 3\n",
    "fold_no = 1\n",
    "#kfold_2 = KFold(n_splits=num_folds, shuffle=True)\n",
    "accuracy_per_fold_2 = []\n",
    "loss_per_fold_2 = []\n",
    "\n",
    "\n",
    "checkpoint_path = os.path.join('../checkpoint/qat', str(subject))\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "     \n",
    "\n",
    "qat_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                            filepath = checkpoint_path, save_best_only=True, monitor='accuracy', vebrose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9b9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "    qat_model = emg_net()\n",
    "    quantizer = vitis_quantize.VitisQuantizer(qat_model, quantize_strategy='8bit_tqt')\n",
    "    qat_model_set = quantizer.get_qat_model(init_quant=True, calib_dataset=calibration_dataset)\n",
    "    \n",
    "    qat_model.compile(optimizer= opt, loss=ls, metrics=mtr)\n",
    "    \n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Quantization Aware Training for fold {fold_no} -------')\n",
    "    \n",
    "    qat_history = qat_model.fit(X_train[train], y_train[train],\n",
    "                                callbacks=[early_stop, qat_checkpoint_callback], batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "    \n",
    "    qat_scores = qat_model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold  {fold_no}: {qat_model.metrics_names[0]} of {qat_scores[0]}; {qat_model.metrics_names[1]} of {qat_scores[1]*100}%')\n",
    "    accuracy_per_fold_2.append(scores[1] *100)\n",
    "    loss_per_fold_2.append(scores[0])\n",
    "          \n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919526ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Average Score per fold \")\n",
    "\n",
    "for i in range(0, len(accuracy_per_fold_2)):\n",
    "    print('-----------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold_2[i]} - Accuracy: {accuracy_per_fold_2[i]}%')\n",
    "print('-----------------------------------------------')\n",
    "print('Average Metrics for all folds: ')\n",
    "print(f'> Accuracy: {np.mean(accuracy_per_fold_2)} (+- {np.std(accuracy_per_fold_2)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold_2)}')\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53849a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model = tf.keras.models.load_model(qat_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f9d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qat_test_loss, qat_test_accuracy = qat_model.evaluate(X_test, y_test)\n",
    "qat_test_accuracy = qat_test_accuracy * 100\n",
    "print(f'Quantization Aware Accuracy {qat_test_accuracy}%')\n",
    "\n",
    "saved_model = '../qat_models/qat-EMG-NET-' + str(subject) + '.h5'\n",
    "qat_model.save(saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed7f26",
   "metadata": {},
   "source": [
    "5. Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8407729e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!vai_c_tensorflow2 \\\n",
    "    --model ../ptq_models/ptq-EMG-NET-33.h5 \\\n",
    "    --arch ./arch_ultra96.json \\\n",
    "    --output_dir ../inference_models \\\n",
    "    --net_name subject_33_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9550df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (8, 40, 1)\n",
    "\n",
    "def emg_net(input_size):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=input_size)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(151, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"BMIS-EMG-NET\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(start_subject=3, stop_subject=4, split_ratio=0.2, no_gesture=7, fs=200, notch_freq=60.0, \n",
    "                    quality_factor=30.0, fc=10.0, fh=99.0,\n",
    "                  order=5, window_time=200, overlap=60, no_channel=8, opt='adam', \n",
    "                   ls='sparse_categorical_crossentropy', mtr='accuracy', n_batches=16, n_epochs=30):\n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        'Subject': [0],\n",
    "        'Validation_result':[0.0],\n",
    "        'qat_Validation_result':[0.0],\n",
    "        'Test_result_32_bit':[0.0],\n",
    "        'Test_result_8_bit_ptq':[0.0],\n",
    "        'Test_result_8_bit_qat':[0.0],\n",
    "        \n",
    "        'precision_full':[0.0],\n",
    "        'recall_full':[0.0],\n",
    "        'f1_score_full':[0.0],\n",
    "\n",
    "        'precision_ptq':[0.0],\n",
    "        'recall_ptq':[0.0],\n",
    "        'f1_score_ptq':[0.0],\n",
    "        \n",
    "        'precision_qat':[0.0],\n",
    "        'recall_qat':[0.0],\n",
    "        'f1_score_qat':[0.0]\n",
    "        })\n",
    "    \n",
    "    data, label = get_data_subject_specific(start_subject, no_gesture, fs, notch_freq, quality_factor, fc, fh, order,\n",
    "                              window_time, overlap, no_channel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, y_train, X_test, y_test = spilt_data(data, label, ratio=split_ratio)\n",
    "        \n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    X_test = np.expand_dims(X_test, axis=3)\n",
    "    input_size = X_train.shape[1:]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for subject in range(start_subject, (stop_subject+1)):\n",
    "        \n",
    "        fold_no = 1\n",
    "        num_folds = 3\n",
    "        accuracy_per_fold = []\n",
    "        loss_per_fold = []\n",
    "        qat_accuracy_per_fold = []\n",
    "        qat_loss_per_fold = []\n",
    "        kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "        \n",
    "        \n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        print(f'Training and Evaluation for subject {subject}')\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        data, label = get_data_subject_specific(subject, no_gesture, fs, notch_freq, quality_factor, fc, fh, order,\n",
    "                              window_time, overlap, no_channel)\n",
    "        \n",
    "        \n",
    "        X_train, y_train, X_test, y_test = spilt_data(data, label, ratio=split_ratio)\n",
    "        \n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "        input_size = X_train.shape[1:]\n",
    "        \n",
    "        calibration_dataset = X_train[0:1000] # Calibration data needed to quantize the model\n",
    "        print(f'Input shape to the EMG-Net Model is: {input_size}')\n",
    "        \n",
    "        for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "            model = emg_net(input_size)\n",
    "            model.compile(optimizer=opt, loss=ls, metrics=mtr)\n",
    "            checkpoint_path = os.path.join('../checkpoint/full', str(subject))\n",
    "\n",
    "            if not os.path.exists(checkpoint_path):\n",
    "                os.makedirs(checkpoint_path)\n",
    "\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "            checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = checkpoint_path, save_best_only=True, monitor='accuracy', vebrose=1)\n",
    "    \n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Training Unquantized Model for fold {fold_no} -------')\n",
    "    \n",
    "            history = model.fit(X_train[train], y_train[train], callbacks=[early_stop, checkpoint_callback], \n",
    "                                batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "    \n",
    "            scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "            print(f'Score for fold  {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "            accuracy_per_fold.append(scores[1] *100)\n",
    "            loss_per_fold.append(scores[0])\n",
    "          \n",
    "            \n",
    "            \n",
    "            print('######################################################')\n",
    "            print('Quantization Aware Training')\n",
    "            \n",
    "            qat_checkpoint_path = os.path.join('../checkpoint/qat', str(subject))\n",
    "\n",
    "            if not os.path.exists(qat_checkpoint_path):\n",
    "                os.makedirs(qat_checkpoint_path)\n",
    "     \n",
    "\n",
    "            qat_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = qat_checkpoint_path, save_best_only=True, monitor='accuracy', vebrose=1)\n",
    "            \n",
    "            qat_model = emg_net(input_size)\n",
    "            quantizer = vitis_quantize.VitisQuantizer(qat_model, quantize_strategy='8bit_tqt')\n",
    "            qat_model_set = quantizer.get_qat_model(init_quant=True, calib_dataset=calibration_dataset)\n",
    "\n",
    "            qat_model.compile(optimizer= opt, loss=ls, metrics=mtr)\n",
    "\n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Quantization Aware Training for fold {fold_no} -------')\n",
    "\n",
    "            qat_history = qat_model.fit(X_train[train], y_train[train],\n",
    "                                        callbacks=[early_stop, qat_checkpoint_callback], \n",
    "                                        batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "\n",
    "            qat_scores = qat_model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "            print(f'QAT Score for fold  {fold_no}: {qat_model.metrics_names[0]} of {qat_scores[0]}; {qat_model.metrics_names[1]} of {qat_scores[1]*100}%')\n",
    "            qat_accuracy_per_fold.append(qat_scores[1] *100)\n",
    "            qat_loss_per_fold.append(scores[0])\n",
    "\n",
    "            fold_no = fold_no + 1\n",
    "        \n",
    "        print(\"Average Full Bit Validation Score per fold \")\n",
    "\n",
    "        for i in range(0, len(accuracy_per_fold)):\n",
    "            print('-----------------------------------------------')\n",
    "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
    "        print('-----------------------------------------------')\n",
    "        print('Average Metrics for all folds: ')\n",
    "        print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
    "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "        print('-----------------------------------------------')\n",
    "        print('############################################################')\n",
    "        print(f'Training Ended for subject {subject}')\n",
    "        print('############################################################')\n",
    "        \n",
    "        validation_result = np.mean(accuracy_per_fold)\n",
    "        qat_validation_result = np.mean(qat_accuracy_per_fold)\n",
    "        \n",
    "        ######### Load the best model from checkpoint. ################\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "        \n",
    "        ############# Evaluating 32-bit Model ##########################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating Unquantized Model')\n",
    "        print('############################################################')\n",
    "        uqt_test_loss, uqt_test_accuracy = model.evaluate(X_test, y_test)\n",
    "        full_test_accuracy = uqt_test_accuracy * 100\n",
    "        print(f'Accuracy of the Unquantized_model {full_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        y_predict = model.predict(X_test)\n",
    "        y_predict = np.argmax(y_predict, axis=-1)\n",
    "   \n",
    "        precision = precision_score(y_test, y_predict, average='weighted')\n",
    "        recall = recall_score(y_test, y_predict, average='weighted')\n",
    "        f1_score_full = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'Precision of the Unquantized model {precision}')\n",
    "        print(f'Recall of the Unquantized model {recall}')\n",
    "        print(f'F1_score of the Unquantized model {f1_score_full}')\n",
    "    \n",
    "        \n",
    "        ############ Save the full model as .h5. This will be used for quantization #####\n",
    "        saved_model = '../full_models/EMG-NET-' + str(subject) + '.h5'\n",
    "        model.save(saved_model)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ############### Post-Training Quantization ########################\n",
    "        saved_float32_model = tf.keras.models.load_model(saved_model)\n",
    "        ptq_quantizer = vitis_quantize.VitisQuantizer(saved_float32_model)\n",
    "        ptq_model = ptq_quantizer.quantize_model(calib_dataset=calibration_dataset)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting PTQ Model #######################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating PTQ Model')\n",
    "        print('############################################################')\n",
    "\n",
    "        ptq_model.compile(loss=ls, metrics=mtr)\n",
    "        ptq_loss, ptq_test_accuracy = ptq_model.evaluate(X_test, y_test)\n",
    "        ptq_test_accuracy = ptq_test_accuracy * 100\n",
    "        print(f'Accuracy of the PTQ model {ptq_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "            \n",
    "        ptq_y_predict = ptq_model.predict(X_test)\n",
    "        ptq_y_predict = np.argmax(ptq_y_predict, axis=-1)\n",
    "        ptq_precision = precision_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_recall = recall_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_f1_score = 2 * (ptq_precision * ptq_recall) / (ptq_precision + ptq_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the PTQ model {ptq_precision}')\n",
    "        print(f'Recall of the PTQ model {ptq_recall}')\n",
    "        print(f'F1_score of the PTQ model {ptq_f1_score}')\n",
    "\n",
    "        # Saving PTQ model; Can be complied for depolyment #######  \n",
    "        ptq_quantized_model = '../ptq_models/ptq-EMG-NET-' + str(subject) + '.h5'\n",
    "        ptq_model.save(ptq_quantized_model)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting QAT Model ###################################\n",
    "        \n",
    "        ## Load Best QAT Model\n",
    "        qat_model = tf.keras.models.load_model(qat_checkpoint_path)\n",
    "        \n",
    "        ## ######### Evaluate QAT Model###############################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating QAT Model')\n",
    "        print('############################################################')\n",
    "        \n",
    "        qat_test_loss, qat_test_accuracy = qat_model.evaluate(X_test, y_test)\n",
    "        qat_test_accuracy = qat_test_accuracy * 100\n",
    "        print(f'Accuracy of the QAT model {qat_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        qat_y_predict = qat_model.predict(X_test)\n",
    "        qat_y_predict = np.argmax(qat_y_predict, axis=-1)\n",
    "        qat_precision = precision_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_recall = recall_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_f1_score = 2 * (qat_precision * qat_recall) / (qat_precision + qat_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the QAT model {qat_precision}')\n",
    "        print(f'Recall of the QAT model {qat_recall}')\n",
    "        print(f'F1_score of the QAT model {qat_f1_score}')\n",
    "        \n",
    "        # Saving QAT model; Can be complied for depolyment #######  \n",
    "        qat_quantized_model = '../qat_models/qat-EMG-NET-' + str(subject) + '.h5'\n",
    "        qat_model.save(qat_quantized_model)\n",
    "        \n",
    "        \n",
    "        result.at[subject-1, 'Subject'] = subject\n",
    "        result.at[subject-1, 'Validation_result'] = validation_result\n",
    "        result.at[subject-1, 'qat_Validation_result'] = qat_validation_result\n",
    "        result.at[subject-1, 'Test_result_32_bit'] = full_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_ptq'] = ptq_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_qat'] = qat_test_accuracy\n",
    "        \n",
    "        result.at[subject-1, 'precision_full'] = precision \n",
    "        result.at[subject-1, 'recall_full'] = recall\n",
    "        result.at[subject-1, 'f1_score_full'] = f1_score_full\n",
    "   \n",
    "        result.at[subject-1, 'precision_ptq'] = ptq_precision \n",
    "        result.at[subject-1, 'recall_ptq'] = ptq_recall\n",
    "        result.at[subject-1, 'f1_score_ptq'] = ptq_f1_score\n",
    "        \n",
    "        result.at[subject-1, 'precision_qat'] = qat_precision \n",
    "        result.at[subject-1, 'recall_qat'] = qat_recall\n",
    "        result.at[subject-1, 'f1_score_qat'] = qat_f1_score\n",
    "\n",
    "        save_path = str(start_subject)+'_to_'+str(stop_subject)+'_EMG_Net.csv'\n",
    "        save_path = os.path.join('../results', save_path)\n",
    "        result.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
