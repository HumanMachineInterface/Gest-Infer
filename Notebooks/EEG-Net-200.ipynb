{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "from bmis_bci_utils import *\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17445e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (8, 50, 1)\n",
    "no_classes = 7\n",
    "\n",
    "\n",
    "def eeg_net(input_size, no_classes):\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = tf.keras.layers.Conv2D(8, 16, padding='same', input_shape=input_size)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(32, 8, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((1,4))(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 16, activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x  =tf.keras.layers.MaxPooling2D((1,8))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(150, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(25, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"BMIS-BCI-NET\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def run_eeg_net_experiment(start_subject=1, stop_subject=33, split_ratio=0.2, no_gesture=7, fs=250, notch_freq=60.0, \n",
    "                    quality_factor=30.0, fc=10.0, fh=50.0,\n",
    "                  order=5, window_time=200, overlap=60, no_channel=8, opt='adam', \n",
    "                   ls='sparse_categorical_crossentropy', mtr='accuracy', n_batches=16, n_epochs=30):\n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        'Subject': [0],\n",
    "        'Validation_result':[0.0],\n",
    "        'qat_Validation_result':[0.0],\n",
    "        'Test_result_32_bit':[0.0],\n",
    "        'Test_result_8_bit_ptq':[0.0],\n",
    "        'Test_result_8_bit_qat':[0.0],\n",
    "        'Kappa_Score':[0.0],\n",
    "        \n",
    "        'precision_full':[0.0],\n",
    "        'recall_full':[0.0],\n",
    "        'f1_score_full':[0.0],\n",
    "\n",
    "        'precision_ptq':[0.0],\n",
    "        'recall_ptq':[0.0],\n",
    "        'f1_score_ptq':[0.0],\n",
    "        \n",
    "        'precision_qat':[0.0],\n",
    "        'recall_qat':[0.0],\n",
    "        'f1_score_qat':[0.0]\n",
    "        })\n",
    "    \n",
    "    '''\n",
    "    data, label = get_data_subject_specific(start_subject)\n",
    "    label = label.reshape(-1)\n",
    "    no_classes = len(np.unique(label))\n",
    "\n",
    "    #print('The total data shape is {} and label is {}'.format(data.shape, label.shape))\n",
    "\n",
    "    X, y = window_with_overlap(data, label, sampling_frequency=fs, window_time=window_size, \n",
    "                               overlap=overlap, no_channel=no_channel)\n",
    "    #print('The total Input data shape after windowing is {} and label is {}'.format(X.shape, y.shape))\n",
    "\n",
    "    X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "    #print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "    print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "        \n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    X_test = np.expand_dims(X_test, axis=3)\n",
    "    input_size = X_train.shape[1:]\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    for subject in range(start_subject, (stop_subject+1)):\n",
    "        \n",
    "        fold_no = 1\n",
    "        num_folds = 3\n",
    "        accuracy_per_fold = []\n",
    "        loss_per_fold = []\n",
    "        \n",
    "        accuracy_per_fold=[]\n",
    "        loss_per_fold=[]\n",
    "        \n",
    "        qat_accuracy_per_fold = []\n",
    "        qat_loss_per_fold = []\n",
    "        kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "        \n",
    "        \n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        print(f'Training and Evaluation for subject {subject} with window size {200}')\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "\n",
    "\n",
    "        data, label = get_data_subject_specific(subject)\n",
    "        label = label.reshape(-1)\n",
    "        no_classes = len(np.unique(label))\n",
    "\n",
    "        #print('The total data shape is {} and label is {}'.format(data.shape, label.shape))\n",
    "\n",
    "        X, y = window_with_overlap(data, label, sampling_frequency=fs, window_time=window_time, \n",
    "                                   overlap=overlap, no_channel=no_channel)\n",
    "        #print('The total Input data shape after windowing is {} and label is {}'.format(X.shape, y.shape))\n",
    "\n",
    "        X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "        #print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "        X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "        print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "        input_size = X_train.shape[1:]\n",
    "        \n",
    "        calibration_dataset = X_train[0:100] # Calibration data needed to quantize the model\n",
    "        print(f'Input shape to the EEG-Net Model is: {input_size}')\n",
    "        \n",
    "        for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "            checkpoint_path = os.path.join('../checkpoint/full/200', str(subject))\n",
    "\n",
    "            if not os.path.exists(checkpoint_path):\n",
    "                os.makedirs(checkpoint_path)\n",
    "\n",
    "\n",
    "            checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = checkpoint_path, save_best_only=True,\n",
    "                                        monitor='accuracy', vebrose=1)\n",
    "    \n",
    "\n",
    "            model_200 = eeg_net(input_size, no_classes)\n",
    "            model_200.compile(optimizer=opt, loss=ls, metrics=mtr)\n",
    "\n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} -------')\n",
    "\n",
    "            history = model_200.fit(X_train[train], y_train[train], callbacks=[early_stop, checkpoint_callback],\n",
    "                                batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "\n",
    "            scores = model_200.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "            print(f'Score for fold  {fold_no}: {model_200.metrics_names[0]} of {scores[0]}; {model_200.metrics_names[1]} of {scores[1]*100}%')\n",
    "            accuracy_per_fold.append(scores[1] *100)\n",
    "            loss_per_fold.append(scores[0])\n",
    "          \n",
    "            \n",
    "            \n",
    "            print('######################################################')\n",
    "            print('Quantization Aware Training')\n",
    "            \n",
    "            qat_checkpoint_path = os.path.join('../checkpoint/qat/200', str(subject))\n",
    "\n",
    "            if not os.path.exists(qat_checkpoint_path):\n",
    "                os.makedirs(qat_checkpoint_path)\n",
    "     \n",
    "\n",
    "            qat_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = qat_checkpoint_path, save_best_only=True, \n",
    "                                        monitor='accuracy', vebrose=1)\n",
    "            \n",
    "            qat_model = eeg_net(input_size, no_classes)\n",
    "            quantizer = vitis_quantize.VitisQuantizer(qat_model, quantize_strategy='8bit_tqt')\n",
    "            qat_model_set = quantizer.get_qat_model(init_quant=True, calib_dataset=calibration_dataset)\n",
    "\n",
    "            qat_model.compile(optimizer= opt, loss=ls, metrics=mtr)\n",
    "\n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Quantization Aware Training for fold {fold_no} -------')\n",
    "\n",
    "            qat_history = qat_model.fit(X_train[train], y_train[train],\n",
    "                                        callbacks=[early_stop, qat_checkpoint_callback], \n",
    "                                        batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "\n",
    "            qat_scores = qat_model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "            print(f'QAT Score for fold  {fold_no}: {qat_model.metrics_names[0]} of {qat_scores[0]}; {qat_model.metrics_names[1]} of {qat_scores[1]*100}%')\n",
    "            qat_accuracy_per_fold.append(qat_scores[1] *100)\n",
    "            qat_loss_per_fold.append(scores[0])\n",
    "\n",
    "            fold_no = fold_no + 1\n",
    "        \n",
    "        print(\"Average Full Bit Validation Score per fold \")\n",
    "\n",
    "        for i in range(0, len(accuracy_per_fold)):\n",
    "            print('-----------------------------------------------')\n",
    "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
    "        print('-----------------------------------------------')\n",
    "        print('Average Metrics for all folds: ')\n",
    "        print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
    "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "        print('-----------------------------------------------')\n",
    "        print('############################################################')\n",
    "        print(f'Training Ended for subject {subject}')\n",
    "        print('############################################################')\n",
    "        \n",
    "        validation_result = np.mean(accuracy_per_fold)\n",
    "        qat_validation_result = np.mean(qat_accuracy_per_fold)\n",
    "        \n",
    "        ######### Load the best model from checkpoint. ################\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "        \n",
    "        ############# Evaluating 32-bit Model ##########################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating Unquantized Model')\n",
    "        print('############################################################')\n",
    "        uqt_test_loss, uqt_test_accuracy = model.evaluate(X_test, y_test)\n",
    "        full_test_accuracy = uqt_test_accuracy * 100\n",
    "        print(f'Accuracy of the Unquantized_model {full_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        y_predict = model.predict(X_test)\n",
    "        y_predict = np.argmax(y_predict, axis=-1)\n",
    "   \n",
    "        precision = precision_score(y_test, y_predict, average='weighted')\n",
    "        recall = recall_score(y_test, y_predict, average='weighted')\n",
    "        f1_score_full = 2 * (precision * recall) / (precision + recall)\n",
    "        kappa_score = cohen_kappa_score(y_test, y_predict)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'Precision of the Unquantized model {precision}')\n",
    "        print(f'Recall of the Unquantized model {recall}')\n",
    "        print(f'F1_score of the Unquantized model {f1_score_full}')\n",
    "        print(f'Kappa_score of the Unquantized model {kappa_score}')\n",
    "    \n",
    "        \n",
    "        ############ Save the full model as .h5. This will be used for quantization #####\n",
    "        saved_model = '../full_models/200/EEG-NET-200-' + str(subject) + '.h5'\n",
    "        model.save(saved_model)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ############### Post-Training Quantization ########################\n",
    "        saved_float32_model = tf.keras.models.load_model(saved_model)\n",
    "        ptq_quantizer = vitis_quantize.VitisQuantizer(saved_float32_model)\n",
    "        ptq_model = ptq_quantizer.quantize_model(calib_dataset=calibration_dataset)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting PTQ Model #######################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating PTQ Model')\n",
    "        print('############################################################')\n",
    "\n",
    "        ptq_model.compile(loss=ls, metrics=mtr)\n",
    "        ptq_loss, ptq_test_accuracy = ptq_model.evaluate(X_test, y_test)\n",
    "        ptq_test_accuracy = ptq_test_accuracy * 100\n",
    "        print(f'Accuracy of the PTQ model {ptq_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "            \n",
    "        ptq_y_predict = ptq_model.predict(X_test)\n",
    "        ptq_y_predict = np.argmax(ptq_y_predict, axis=-1)\n",
    "        ptq_precision = precision_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_recall = recall_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_f1_score = 2 * (ptq_precision * ptq_recall) / (ptq_precision + ptq_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the PTQ model {ptq_precision}')\n",
    "        print(f'Recall of the PTQ model {ptq_recall}')\n",
    "        print(f'F1_score of the PTQ model {ptq_f1_score}')\n",
    "\n",
    "        # Saving PTQ model; Can be complied for depolyment #######  \n",
    "        ptq_quantized_model = '../ptq_models/200/ptq-EEG-NET-' + str(subject) + '.h5'\n",
    "        ptq_model.save(ptq_quantized_model)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting QAT Model ###################################\n",
    "        \n",
    "        ## Load Best QAT Model\n",
    "        qat_model = tf.keras.models.load_model(qat_checkpoint_path)\n",
    "        \n",
    "        ## ######### Evaluate QAT Model###############################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating QAT Model')\n",
    "        print('############################################################')\n",
    "        \n",
    "        qat_test_loss, qat_test_accuracy = qat_model.evaluate(X_test, y_test)\n",
    "        qat_test_accuracy = qat_test_accuracy * 100\n",
    "        print(f'Accuracy of the QAT model {qat_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        qat_y_predict = qat_model.predict(X_test)\n",
    "        qat_y_predict = np.argmax(qat_y_predict, axis=-1)\n",
    "        qat_precision = precision_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_recall = recall_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_f1_score = 2 * (qat_precision * qat_recall) / (qat_precision + qat_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the QAT model {qat_precision}')\n",
    "        print(f'Recall of the QAT model {qat_recall}')\n",
    "        print(f'F1_score of the QAT model {qat_f1_score}')\n",
    "        \n",
    "        # Saving QAT model; Can be complied for depolyment #######  \n",
    "        qat_quantized_model = '../qat_models/200/qat-EEG-NET-' + str(subject) + '.h5'\n",
    "        qat_model.save(qat_quantized_model)\n",
    "        \n",
    "        \n",
    "        result.at[subject-1, 'Subject'] = subject\n",
    "        result.at[subject-1, 'Validation_result'] = validation_result\n",
    "        result.at[subject-1, 'qat_Validation_result'] = qat_validation_result\n",
    "        result.at[subject-1, 'Test_result_32_bit'] = full_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_ptq'] = ptq_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_qat'] = qat_test_accuracy\n",
    "        result.at[subject-1, 'Kappa_Score'] = kappa_score      \n",
    "        \n",
    "        result.at[subject-1, 'precision_full'] = precision \n",
    "        result.at[subject-1, 'recall_full'] = recall\n",
    "        result.at[subject-1, 'f1_score_full'] = f1_score_full\n",
    "   \n",
    "        result.at[subject-1, 'precision_ptq'] = ptq_precision \n",
    "        result.at[subject-1, 'recall_ptq'] = ptq_recall\n",
    "        result.at[subject-1, 'f1_score_ptq'] = ptq_f1_score\n",
    "        \n",
    "        result.at[subject-1, 'precision_qat'] = qat_precision \n",
    "        result.at[subject-1, 'recall_qat'] = qat_recall\n",
    "        result.at[subject-1, 'f1_score_qat'] = qat_f1_score\n",
    "\n",
    "        save_path = str(start_subject)+'_to_'+str(stop_subject)+'_EEG_Net.csv'\n",
    "        save_path = os.path.join('../results/200', save_path)\n",
    "        result.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3606a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eeg_net_experiment(start_subject=12, stop_subject=33, split_ratio=0.2, no_gesture=7, fs=250, notch_freq=60.0, \n",
    "                    quality_factor=30.0, fc=10.0, fh=50.0,\n",
    "                    order=5, window_time=200, overlap=60, no_channel=8, opt='adam', \n",
    "                    ls='sparse_categorical_crossentropy', mtr='accuracy', n_batches=16, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5ef6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!vai_c_tensorflow2 \\\n",
    "    --model ../ptq_models/200/ptq-EEG-NET-33.h5 \\\n",
    "    --arch ./arch_ultra96.json \\\n",
    "    --output_dir ../inference_models \\\n",
    "    --net_name subject_33_model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
