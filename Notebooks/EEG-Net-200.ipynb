{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac8441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 23:40:04.555908: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu\n",
      "2023-06-05 23:40:04.555921: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "from bmis_bci_utils import *\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17445e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (8, 50, 1)\n",
    "no_classes = 7\n",
    "\n",
    "\n",
    "def eeg_net(input_size, no_classes):\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = tf.keras.layers.Conv2D(8, 16, padding='same', input_shape=input_size)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(32, 8, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((1,4))(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 16, activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x  =tf.keras.layers.MaxPooling2D((1,8))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(150, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(25, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"BMIS-BCI-NET\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def run_eeg_net_experiment(start_subject=1, stop_subject=33, split_ratio=0.2, no_gesture=7, fs=250, notch_freq=60.0, \n",
    "                    quality_factor=30.0, fc=10.0, fh=50.0,\n",
    "                  order=5, window_time=200, overlap=60, no_channel=8, opt='adam', \n",
    "                   ls='sparse_categorical_crossentropy', mtr='accuracy', n_batches=16, n_epochs=30):\n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        'Subject': [0],\n",
    "        'Validation_result':[0.0],\n",
    "        'qat_Validation_result':[0.0],\n",
    "        'Test_result_32_bit':[0.0],\n",
    "        'Test_result_8_bit_ptq':[0.0],\n",
    "        'Test_result_8_bit_qat':[0.0],\n",
    "        'Kappa_Score':[0.0],\n",
    "        \n",
    "        'precision_full':[0.0],\n",
    "        'recall_full':[0.0],\n",
    "        'f1_score_full':[0.0],\n",
    "\n",
    "        'precision_ptq':[0.0],\n",
    "        'recall_ptq':[0.0],\n",
    "        'f1_score_ptq':[0.0],\n",
    "        \n",
    "        'precision_qat':[0.0],\n",
    "        'recall_qat':[0.0],\n",
    "        'f1_score_qat':[0.0]\n",
    "        })\n",
    "    \n",
    "    '''\n",
    "    data, label = get_data_subject_specific(start_subject)\n",
    "    label = label.reshape(-1)\n",
    "    no_classes = len(np.unique(label))\n",
    "\n",
    "    #print('The total data shape is {} and label is {}'.format(data.shape, label.shape))\n",
    "\n",
    "    X, y = window_with_overlap(data, label, sampling_frequency=fs, window_time=window_size, \n",
    "                               overlap=overlap, no_channel=no_channel)\n",
    "    #print('The total Input data shape after windowing is {} and label is {}'.format(X.shape, y.shape))\n",
    "\n",
    "    X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "    #print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "    print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "        \n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    X_test = np.expand_dims(X_test, axis=3)\n",
    "    input_size = X_train.shape[1:]\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    for subject in range(start_subject, (stop_subject+1)):\n",
    "        \n",
    "        fold_no = 1\n",
    "        num_folds = 3\n",
    "        accuracy_per_fold = []\n",
    "        loss_per_fold = []\n",
    "        \n",
    "        accuracy_per_fold=[]\n",
    "        loss_per_fold=[]\n",
    "        \n",
    "        qat_accuracy_per_fold = []\n",
    "        qat_loss_per_fold = []\n",
    "        kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "        \n",
    "        \n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        print(f'Training and Evaluation for subject {subject} with window size {200}')\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "\n",
    "\n",
    "        data, label = get_data_subject_specific(subject)\n",
    "        label = label.reshape(-1)\n",
    "        no_classes = len(np.unique(label))\n",
    "\n",
    "        #print('The total data shape is {} and label is {}'.format(data.shape, label.shape))\n",
    "\n",
    "        X, y = window_with_overlap(data, label, sampling_frequency=fs, window_time=window_time, \n",
    "                                   overlap=overlap, no_channel=no_channel)\n",
    "        #print('The total Input data shape after windowing is {} and label is {}'.format(X.shape, y.shape))\n",
    "\n",
    "        X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "        #print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "        X_train, y_train, X_test, y_test = spilt_data(X, y, ratio=split_ratio)\n",
    "        print('Training Set is{} Test Set {}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "        input_size = X_train.shape[1:]\n",
    "        \n",
    "        calibration_dataset = X_train[0:100] # Calibration data needed to quantize the model\n",
    "        print(f'Input shape to the EEG-Net Model is: {input_size}')\n",
    "        \n",
    "        for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "            checkpoint_path = os.path.join('../checkpoint/full/200', str(subject))\n",
    "\n",
    "            if not os.path.exists(checkpoint_path):\n",
    "                os.makedirs(checkpoint_path)\n",
    "\n",
    "\n",
    "            checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = checkpoint_path, save_best_only=True,\n",
    "                                        monitor='accuracy', vebrose=1)\n",
    "    \n",
    "\n",
    "            model_200 = eeg_net(input_size, no_classes)\n",
    "            model_200.compile(optimizer=opt, loss=ls, metrics=mtr)\n",
    "\n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} -------')\n",
    "\n",
    "            history = model_200.fit(X_train[train], y_train[train], callbacks=[early_stop, checkpoint_callback],\n",
    "                                batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "\n",
    "            scores = model_200.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "            print(f'Score for fold  {fold_no}: {model_200.metrics_names[0]} of {scores[0]}; {model_200.metrics_names[1]} of {scores[1]*100}%')\n",
    "            accuracy_per_fold.append(scores[1] *100)\n",
    "            loss_per_fold.append(scores[0])\n",
    "          \n",
    "            \n",
    "            \n",
    "            print('######################################################')\n",
    "            print('Quantization Aware Training')\n",
    "            \n",
    "            qat_checkpoint_path = os.path.join('../checkpoint/qat/200', str(subject))\n",
    "\n",
    "            if not os.path.exists(qat_checkpoint_path):\n",
    "                os.makedirs(qat_checkpoint_path)\n",
    "     \n",
    "\n",
    "            qat_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = qat_checkpoint_path, save_best_only=True, \n",
    "                                        monitor='accuracy', vebrose=1)\n",
    "            \n",
    "            qat_model = eeg_net(input_size, no_classes)\n",
    "            quantizer = vitis_quantize.VitisQuantizer(qat_model, quantize_strategy='8bit_tqt')\n",
    "            qat_model_set = quantizer.get_qat_model(init_quant=True, calib_dataset=calibration_dataset)\n",
    "\n",
    "            qat_model.compile(optimizer= opt, loss=ls, metrics=mtr)\n",
    "\n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Quantization Aware Training for fold {fold_no} -------')\n",
    "\n",
    "            qat_history = qat_model.fit(X_train[train], y_train[train],\n",
    "                                        callbacks=[early_stop, qat_checkpoint_callback], \n",
    "                                        batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "\n",
    "            qat_scores = qat_model.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "            print(f'QAT Score for fold  {fold_no}: {qat_model.metrics_names[0]} of {qat_scores[0]}; {qat_model.metrics_names[1]} of {qat_scores[1]*100}%')\n",
    "            qat_accuracy_per_fold.append(qat_scores[1] *100)\n",
    "            qat_loss_per_fold.append(scores[0])\n",
    "\n",
    "            fold_no = fold_no + 1\n",
    "        \n",
    "        print(\"Average Full Bit Validation Score per fold \")\n",
    "\n",
    "        for i in range(0, len(accuracy_per_fold)):\n",
    "            print('-----------------------------------------------')\n",
    "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
    "        print('-----------------------------------------------')\n",
    "        print('Average Metrics for all folds: ')\n",
    "        print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
    "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "        print('-----------------------------------------------')\n",
    "        print('############################################################')\n",
    "        print(f'Training Ended for subject {subject}')\n",
    "        print('############################################################')\n",
    "        \n",
    "        validation_result = np.mean(accuracy_per_fold)\n",
    "        qat_validation_result = np.mean(qat_accuracy_per_fold)\n",
    "        \n",
    "        ######### Load the best model from checkpoint. ################\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "        \n",
    "        ############# Evaluating 32-bit Model ##########################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating Unquantized Model')\n",
    "        print('############################################################')\n",
    "        uqt_test_loss, uqt_test_accuracy = model.evaluate(X_test, y_test)\n",
    "        full_test_accuracy = uqt_test_accuracy * 100\n",
    "        print(f'Accuracy of the Unquantized_model {full_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        y_predict = model.predict(X_test)\n",
    "        y_predict = np.argmax(y_predict, axis=-1)\n",
    "   \n",
    "        precision = precision_score(y_test, y_predict, average='weighted')\n",
    "        recall = recall_score(y_test, y_predict, average='weighted')\n",
    "        f1_score_full = 2 * (precision * recall) / (precision + recall)\n",
    "        kappa_score = cohen_kappa_score(y_test, y_predict)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'Precision of the Unquantized model {precision}')\n",
    "        print(f'Recall of the Unquantized model {recall}')\n",
    "        print(f'F1_score of the Unquantized model {f1_score_full}')\n",
    "        print(f'Kappa_score of the Unquantized model {kappa_score}')\n",
    "    \n",
    "        \n",
    "        ############ Save the full model as .h5. This will be used for quantization #####\n",
    "        saved_model = '../full_models/200/EEG-NET-200-' + str(subject) + '.h5'\n",
    "        model.save(saved_model)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ############### Post-Training Quantization ########################\n",
    "        saved_float32_model = tf.keras.models.load_model(saved_model)\n",
    "        ptq_quantizer = vitis_quantize.VitisQuantizer(saved_float32_model)\n",
    "        ptq_model = ptq_quantizer.quantize_model(calib_dataset=calibration_dataset)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting PTQ Model #######################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating PTQ Model')\n",
    "        print('############################################################')\n",
    "\n",
    "        ptq_model.compile(loss=ls, metrics=mtr)\n",
    "        ptq_loss, ptq_test_accuracy = ptq_model.evaluate(X_test, y_test)\n",
    "        ptq_test_accuracy = ptq_test_accuracy * 100\n",
    "        print(f'Accuracy of the PTQ model {ptq_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "            \n",
    "        ptq_y_predict = ptq_model.predict(X_test)\n",
    "        ptq_y_predict = np.argmax(ptq_y_predict, axis=-1)\n",
    "        ptq_precision = precision_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_recall = recall_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_f1_score = 2 * (ptq_precision * ptq_recall) / (ptq_precision + ptq_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the PTQ model {ptq_precision}')\n",
    "        print(f'Recall of the PTQ model {ptq_recall}')\n",
    "        print(f'F1_score of the PTQ model {ptq_f1_score}')\n",
    "\n",
    "        # Saving PTQ model; Can be complied for depolyment #######  \n",
    "        ptq_quantized_model = '../ptq_models/200/ptq-EEG-NET-' + str(subject) + '.h5'\n",
    "        ptq_model.save(ptq_quantized_model)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting QAT Model ###################################\n",
    "        \n",
    "        ## Load Best QAT Model\n",
    "        qat_model = tf.keras.models.load_model(qat_checkpoint_path)\n",
    "        \n",
    "        ## ######### Evaluate QAT Model###############################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating QAT Model')\n",
    "        print('############################################################')\n",
    "        \n",
    "        qat_test_loss, qat_test_accuracy = qat_model.evaluate(X_test, y_test)\n",
    "        qat_test_accuracy = qat_test_accuracy * 100\n",
    "        print(f'Accuracy of the QAT model {qat_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        qat_y_predict = qat_model.predict(X_test)\n",
    "        qat_y_predict = np.argmax(qat_y_predict, axis=-1)\n",
    "        qat_precision = precision_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_recall = recall_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_f1_score = 2 * (qat_precision * qat_recall) / (qat_precision + qat_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the QAT model {qat_precision}')\n",
    "        print(f'Recall of the QAT model {qat_recall}')\n",
    "        print(f'F1_score of the QAT model {qat_f1_score}')\n",
    "        \n",
    "        # Saving QAT model; Can be complied for depolyment #######  \n",
    "        qat_quantized_model = '../qat_models/200/qat-EEG-NET-' + str(subject) + '.h5'\n",
    "        qat_model.save(qat_quantized_model)\n",
    "        \n",
    "        \n",
    "        result.at[subject-1, 'Subject'] = subject\n",
    "        result.at[subject-1, 'Validation_result'] = validation_result\n",
    "        result.at[subject-1, 'qat_Validation_result'] = qat_validation_result\n",
    "        result.at[subject-1, 'Test_result_32_bit'] = full_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_ptq'] = ptq_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_qat'] = qat_test_accuracy\n",
    "        result.at[subject-1, 'Kappa_Score'] = kappa_score      \n",
    "        \n",
    "        result.at[subject-1, 'precision_full'] = precision \n",
    "        result.at[subject-1, 'recall_full'] = recall\n",
    "        result.at[subject-1, 'f1_score_full'] = f1_score_full\n",
    "   \n",
    "        result.at[subject-1, 'precision_ptq'] = ptq_precision \n",
    "        result.at[subject-1, 'recall_ptq'] = ptq_recall\n",
    "        result.at[subject-1, 'f1_score_ptq'] = ptq_f1_score\n",
    "        \n",
    "        result.at[subject-1, 'precision_qat'] = qat_precision \n",
    "        result.at[subject-1, 'recall_qat'] = qat_recall\n",
    "        result.at[subject-1, 'f1_score_qat'] = qat_f1_score\n",
    "\n",
    "        save_path = str(start_subject)+'_to_'+str(stop_subject)+'_EEG_Net.csv'\n",
    "        save_path = os.path.join('../results/200', save_path)\n",
    "        result.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3606a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Training and Evaluation for subject 12 with window size 200\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Training Set is(2098, 8, 50) Test Set (525, 8, 50)\n",
      "Input shape to the EEG-Net Model is: (8, 50, 1)\n",
      "---------------------------------------------------\n",
      "Training for fold 1 -------\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 23:40:06.224882: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu\n",
      "2023-06-05 23:40:06.224895: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-05 23:40:06.224915: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-06-05 23:40:06.225041: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/88 [===========================>..] - ETA: 0s - loss: 2.0103 - accuracy: 0.1510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 23:40:07.864485: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../checkpoint/full/200/12/assets\n",
      "88/88 [==============================] - 2s 20ms/step - loss: 2.0079 - accuracy: 0.1531\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 1.9548 - accuracy: 0.1524\n",
      "Epoch 3/50\n",
      "86/88 [============================>.] - ETA: 0s - loss: 1.9250 - accuracy: 0.1781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43434/1729001752.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mquality_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     ls='sparse_categorical_crossentropy', mtr='accuracy', n_batches=16, n_epochs=50)\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_43434/2049636142.py\u001b[0m in \u001b[0;36mrun_eeg_net_experiment\u001b[0;34m(start_subject, stop_subject, split_ratio, no_gesture, fs, notch_freq, quality_factor, fc, fh, order, window_time, overlap, no_channel, opt, ls, mtr, n_batches, n_epochs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             history = model_200.fit(X_train[train], y_train[train], callbacks=[early_stop, checkpoint_callback],\n\u001b[0;32m--> 141\u001b[0;31m                                 batch_size=n_batches, epochs= n_epochs, verbose=1)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_200\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[1;32m   1442\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2385\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtraceback_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 152\u001b[0;31m                             signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0;32m---> 94\u001b[0;31m           model, filepath, signatures, options)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Save all metadata to a separate file in the SavedModel directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1369\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1370\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1371\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1486\u001b[0m   \u001b[0;31m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m   saveable_view = _SaveableView(checkpoint_graph_view, options,\n\u001b[0;32m-> 1488\u001b[0;31m                                 wrapped_functions)\n\u001b[0m\u001b[1;32m   1489\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m   asset_info, exported_graph = _fill_meta_graph_def(\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_view, options, wrapped_functions)\u001b[0m\n\u001b[1;32m    197\u001b[0m     (self._trackable_objects, self.node_paths, self.node_ids,\n\u001b[1;32m    198\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m          self.checkpoint_view.objects_ids_and_slot_variables_and_paths())\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_save_and_restore_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mobjects_ids_and_slot_variables_and_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m                   object -> node id, slot variables, object_names)\n\u001b[1;32m    605\u001b[0m     \"\"\"\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0mtrackable_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_breadth_first_traversal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m     \u001b[0mobject_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36m_breadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m       \u001b[0mcurrent_trackable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_visit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbfs_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_trackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_trackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           node_paths[dependency] = (\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    134\u001b[0m               \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m               \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m               cache=self._serialization_cache))\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     children = [base.TrackableReference(name, ref) for name, ref\n\u001b[0;32m--> 256\u001b[0;31m                 in obj._trackable_children(save_type, **kwargs).items()]\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msave_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_legacy_saved_model_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m       raise ValueError(\"Unexpected format passed to `_trackable_children`. \"\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_get_legacy_saved_model_children\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0;31m# Retrieve functions attached to the object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m     \u001b[0;31m# Trace concrete functions to force side-effects:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   3167\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3168\u001b[0m     return (self._trackable_saved_model_saver\n\u001b[0;32m-> 3169\u001b[0;31m             .list_functions_for_serialization(serialization_cache))\n\u001b[0m\u001b[1;32m   3170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3171\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mlist_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     98\u001b[0m     fns.update(\n\u001b[1;32m     99\u001b[0m         tf.__internal__.tracking.AutoTrackable._list_functions_for_serialization(  # pylint:disable=protected-access\n\u001b[0;32m--> 100\u001b[0;31m             self.obj, serialization_cache))\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow/python/training/tracking/autotrackable.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, unused_serialization_cache)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mattribute_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m           \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mattribute_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/warnings.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters_mutated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showwarning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowwarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showwarnmsg_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showwarnmsg_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_eeg_net_experiment(start_subject=12, stop_subject=33, split_ratio=0.2, no_gesture=7, fs=250, notch_freq=60.0, \n",
    "                    quality_factor=30.0, fc=10.0, fh=50.0,\n",
    "                    order=5, window_time=200, overlap=60, no_channel=8, opt='adam', \n",
    "                    ls='sparse_categorical_crossentropy', mtr='accuracy', n_batches=16, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75b5ef6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['../ptq_models/200/ptq-EEG-NET-33.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/subject_33_model_0x101000016010404_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/EEG/quantized_BCI_NET/ptq_models/200/ptq-EEG-NET-33.h5\n",
      "[INFO] keras version: 2.8.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|| 18/18 [00:00<00:00, 8815.68it/s]            \n",
      "[INFO] infer shape (NHWC)  :100%|| 34/34 [00:00<00:00, 50390.93it/s]           \n",
      "[INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 660.83it/s]               \n",
      "[INFO] perform level-1 opt :100%|| 2/2 [00:00<00:00, 2593.08it/s]              \n",
      "[INFO] generate xmodel     :100%|| 34/34 [00:00<00:00, 5415.70it/s]            \n",
      "[INFO] dump xmodel: /tmp/subject_33_model_0x101000016010404_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: function\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA1_B1600\n",
      "[UNILOG][INFO] Graph name: BMIS-BCI-NET, with op num: 60\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/EEG/quantized_BCI_NET/code/../inference_models/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/EEG/quantized_BCI_NET/code/../inference_models/subject_33_model.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is 8241d222ae6a2e2674378e0bc8746f0a, and has been saved to \"/workspace/EEG/quantized_BCI_NET/code/../inference_models/md5sum.txt\"\n"
     ]
    }
   ],
   "source": [
    "!vai_c_tensorflow2 \\\n",
    "    --model ../ptq_models/200/ptq-EEG-NET-33.h5 \\\n",
    "    --arch ./arch_ultra96.json \\\n",
    "    --output_dir ../inference_models \\\n",
    "    --net_name subject_33_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26263e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_on_device_data(start_subject, end_subject):\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    for subject in range(start_subject, end_subject+1):\n",
    "        \n",
    "        fs = 250\n",
    "\n",
    "        notch_freq = 60.0\n",
    "        quality_factor = 30.0\n",
    "        fc = 10.0\n",
    "        fh = 99.0\n",
    "        order = 5\n",
    "        window_time = 200\n",
    "        overlap = 50\n",
    "        no_channel = 8\n",
    "\n",
    "        no_gesture = 7\n",
    "        concat_data = []\n",
    "        concat_label = []\n",
    "        on_device_data_path = '../on-device/data/' + str(subject) + '.mat'\n",
    "        \n",
    "        data, label = get_data_subject_specific(subject)\n",
    "        label = label.reshape(-1)\n",
    "        no_classes = len(np.unique(label))\n",
    "\n",
    "        #print('The total data shape is {} and label is {}'.format(data.shape, label.shape))\n",
    "\n",
    "        X, y = window_with_overlap(data, label, sampling_frequency=fs, window_time=window_time, \n",
    "                                   overlap=overlap, no_channel=no_channel)    \n",
    "        \n",
    "        data = X\n",
    "        label = y\n",
    "\n",
    "        for i in range(no_gesture):\n",
    "            random_items = np.random.choice(np.where(np.squeeze(label == i))[0], size=5, replace=False)\n",
    "            on_device_data = data[random_items]\n",
    "            on_device_label = label[random_items]\n",
    "\n",
    "            concat_data.append(on_device_data)\n",
    "            concat_label.append(on_device_label)\n",
    "\n",
    "        new_data = np.concatenate(concat_data, axis=0)\n",
    "        new_label = np.concatenate(concat_label, axis=0)   \n",
    "        \n",
    "        new_data, new_label = shuffle_data(new_data, new_label)\n",
    "        \n",
    "        data_dict = {'data': new_data, 'label':new_label}\n",
    "        \n",
    "        \n",
    "        scipy.io.savemat(on_device_data_path, data_dict)\n",
    "    \n",
    "    print('%%%% Finished Storing Data%%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a732d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data, label):\n",
    "    idx = np.random.permutation(len(data))\n",
    "    x, y = data[idx], label[idx]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2195789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%% Finished Storing Data%%%\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "save_on_device_data(start_subject=12, end_subject=33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
