{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a5cfc8",
   "metadata": {},
   "source": [
    "This script includes the CNN based network to train, quantize and compile model used for gesture \n",
    "recognition from Electromyograpgy( EMG ) and Electrnecephalography (EEG). The EMG data was acquired using the commercial Myo-Armband, while the EEG data was acquired using the OPenBCI ultracortex \"Mark IV\" \n",
    "\n",
    "(https://docs.openbci.com/AddOns/Headwear/MarkIV/#:~:text=The%20Ultracortex%20is%20an%20open,love%20to%20hear%20your%20feedback.). Myo-Armband has a sampling frequency of 200Hz with 8 channels placed on the forearm while the ULtracortex has a sampling frequency of 250Hz. \n",
    "\n",
    "Below are the steps.\n",
    "1. Importing and Pre-processing --> This step also includes notching the input signal at 60Hz and windowig with over. Because the DPU engine require three channel input, the shape of the data is expanded to fit DPU requirement. \n",
    "\n",
    "2. Training --> After setting the hyperparamters,the architecture was defined and the trained using tensorflow 2.* Therafter the accuracy of the model was visualized to confirm performance. \n",
    "\n",
    "3. Quantization --> Post training quantization was implemented in this script using the Vitis-AI tool. The quantizer reduces the precision of 32 bit floating point to 8-bit fixed point.\n",
    "\n",
    "4. Compling --> The subgraph needed to be complied to produce .xmodel format after would later to deployed to the Xilix FPGA (Ultra-96 v2) as an overlay in Pynq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend\n",
    "#!pip install tensorflow-addons\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from bmis_hybrid_utils import *\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f571504",
   "metadata": {},
   "source": [
    " 1. Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 33\n",
    "\n",
    "no_gesture = 7\n",
    "\n",
    "emg_fs = 200\n",
    "eeg_fs = 250\n",
    "\n",
    "notch_freq = 60.0\n",
    "quality_factor = 30.0\n",
    "\n",
    "\n",
    "eeg_fc = 10.0\n",
    "eeg_fh = 35.0\n",
    "\n",
    "emg_fc = 10.0\n",
    "emg_fh = 99.0\n",
    "\n",
    "order = 5\n",
    "window_time = 200\n",
    "overlap = 60\n",
    "no_channel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b016832",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_data, eeg_data, label = get_data_subject_specific(subject, no_gesture, emg_fs, eeg_fs,\n",
    "                                                      notch_freq, quality_factor, emg_fc, emg_fh, \n",
    "                                                      eeg_fc, eeg_fh, order,\n",
    "                                                      window_time, overlap, no_channel)\n",
    "\n",
    "print(f'Total EMG data is {emg_data.shape} EEG data is {eeg_data.shape} Label {label.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16825e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG data split check this well\n",
    "X_emg_train, y_train, X_emg_test, y_test = spilt_data(emg_data, label, ratio=0.1)\n",
    "print('EMG Training Set is{} Test Set {}'.format(X_emg_train.shape, X_emg_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG data split\n",
    "X_eeg_train, _, X_eeg_test, _ = spilt_data(eeg_data, label, ratio=0.1)\n",
    "print('EEG Training Set is{} Test Set {}'.format(X_eeg_train.shape, X_eeg_test.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e061efdb",
   "metadata": {},
   "source": [
    "X_eeg_train = X_eeg_train[:len(X_emg_train)]\n",
    "X_eeg_test = X_eeg_train[:len(X_emg_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e8c5c",
   "metadata": {},
   "source": [
    " 2. Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling EEG\n",
    "X_eeg_train = downsample_data(data=X_eeg_train, nfs=emg_fs, window_time=window_time)\n",
    "X_eeg_test = downsample_data(data=X_eeg_test, nfs=emg_fs, window_time=window_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14111bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Resampled EEG training data is: {X_eeg_train.shape}')\n",
    "print(f'Resampled EEG test data is: {X_eeg_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a805503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the input feature shape for EMG\n",
    "X_emg_train = np.expand_dims(X_emg_train, axis=3)\n",
    "X_emg_test = np.expand_dims(X_emg_test, axis=3)\n",
    "print('Expanded Dimension are {}'.format(X_emg_train.shape))\n",
    "input_size = X_emg_train.shape[1:]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the input feature shape for EEG\n",
    "X_eeg_train = np.expand_dims(X_eeg_train, axis=3)\n",
    "X_eeg_test = np.expand_dims(X_eeg_test, axis=3)\n",
    "print('Expanded Dimension are {}'.format(X_eeg_train.shape))\n",
    "input_size = X_emg_train.shape[1:]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af469d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_list = ['LDG', 'MRDG', 'TFSG', 'PPG', 'PG', 'Cut', 'Rest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b922e6c",
   "metadata": {},
   "source": [
    "3. Importing Pre-trained model for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835225bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emg_model_path = '/workspace/sEMG/BMIS_EMG_DATA/full_models'\n",
    "emg_subject = 'EMG-NET-' + str(subject) + '.h5'\n",
    "base_model_path = os.path.join(emg_model_path, emg_subject)\n",
    "base_model = tf.keras.models.load_model(base_model_path)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3801ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.Model(inputs=base_model.inputs, outputs=[layer.output for layer in base_model.layers[0:5]])\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5efc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_input=base_model.inputs\n",
    "intermediate=[layer.output for layer in base_model.layers[1:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_net(input_size, eeg_input, intermediate):\n",
    "    \n",
    "    \n",
    "    emg_input = tf.keras.Input(shape=input_size,  name=\"emg\")\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=input_size)(emg_input)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    emg_output = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    \n",
    "    \n",
    "    x = intermediate[-1]\n",
    "    eeg_output = x\n",
    "  \n",
    "    \n",
    "    concat = tf.keras.layers.concatenate([emg_output, eeg_output])\n",
    "    \n",
    "    down_stream_layer = tf.keras.layers.Flatten()(concat)\n",
    "    down_stream_layer = tf.keras.layers.Dropout(0.5)(down_stream_layer)\n",
    "    down_stream_layer = tf.keras.layers.Dense(100, activation='relu')(down_stream_layer)\n",
    "    down_stream_layer = tf.keras.layers.Dense(25, activation='relu')(down_stream_layer)\n",
    "    output = tf.keras.layers.Dense(7, activation='softmax')(down_stream_layer)\n",
    "    \n",
    "    hybrid_net = tf.keras.Model([emg_input, eeg_input], output, name='BMIS_Hybrid_Net')\n",
    "    \n",
    "    return hybrid_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11febefa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = hybrid_net(input_size, eeg_input, intermediate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {'emg':X_emg_train, 'eeg':X_eeg_train}\n",
    "X_test = {'emg':X_emg_test, 'eeg':X_eeg_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "opt = 'adam'\n",
    "ls = 'sparse_categorical_crossentropy'\n",
    "mtr = 'accuracy'\n",
    "n_batches = 32\n",
    "n_epochs = 50\n",
    "#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
    "model.compile(optimizer=opt, loss=ls, metrics=mtr)\n",
    "num_folds = 3\n",
    "fold_no = 1\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "accuracy_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961233d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train, test in kfold.split(X_train['emg'], y_train):\n",
    "    \n",
    "    model = hybrid_net(input_size, eeg_input, intermediate)\n",
    "    model.compile(optimizer=opt, loss=ls, metrics=mtr)\n",
    "    \n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} -------')\n",
    "    \n",
    "    history = model.fit((X_train['emg'][train],X_train['eeg'][train]),\n",
    "                        y_train[train], batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "    \n",
    "    scores = model.evaluate((X_train['emg'][test],X_train['eeg'][test]), y_train[test], verbose=0)\n",
    "    print(f'Score for fold  {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    accuracy_per_fold.append(scores[1] *100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "          \n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64385e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Score per fold \")\n",
    "\n",
    "for i in range(0, len(accuracy_per_fold)):\n",
    "    print('-----------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
    "print('-----------------------------------------------')\n",
    "print('Average Metrics for all folds: ')\n",
    "print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e922a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"single-Subject-HYBRID-NET.h5\" \n",
    "model.save(saved_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86a20e8a",
   "metadata": {},
   "source": [
    "POST TRAINING QUANTIZATION (Int-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_sample = 1000\n",
    "calibration_data = (X_train['emg'][calibration_sample],X_train['eeg'][calibration_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc873b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saved_float32_model = tf.keras.models.load_model(saved_model)\n",
    "ptq_quantizer = vitis_quantize.VitisQuantizer(saved_float32_model)\n",
    "ptq_quantized_model = ptq_quantizer.quantize_model(calib_dataset=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalauting Post training quantization\n",
    "\n",
    "ptq_quantized_model.compile(loss=ls, metrics=mtr)\n",
    "ptq_quantized_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = \"single-Subject-quantized-HYBRID-NET.h5\"\n",
    "ptq_quantized_model.save(quantized_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f79c5ac7",
   "metadata": {},
   "source": [
    "Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28edabc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!vai_c_tensorflow2 \\\n",
    "    --model ../ptq_models/ptq-Hybrid-Net-33.h5 \\\n",
    "    --arch ./arch_ultra96.json \\\n",
    "    --output_dir ../inference_models \\\n",
    "    --net_name subject_33_model "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef0f6514",
   "metadata": {},
   "source": [
    "Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eda2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 3\n",
    "fold_no = 1\n",
    "kfold_2 = KFold(n_splits=num_folds, shuffle=False)\n",
    "accuracy_per_fold_2 = []\n",
    "loss_per_fold_2 = []\n",
    "n_epochs = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kfold_2.split(X_train['emg'], y_train):\n",
    "    \n",
    "    qat_model = hybrid_net()\n",
    "    quantizer = vitis_quantize.VitisQuantizer(qat_model, quantize_strategy='8bit_tqt')\n",
    "    qat_model_set = quantizer.get_qat_model(init_quant=True, calib_dataset=X_train)\n",
    "    \n",
    "    qat_model.compile(optimizer= opt, loss=ls, metrics=mtr)\n",
    "    \n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Quantization Aware Training for fold {fold_no} -------')\n",
    "    \n",
    "    history = qat_model.fit((X_train['emg'][train],X_train['eeg'][train]), y_train[train], batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "    \n",
    "    scores = qat_model.evaluate((X_train['emg'][test],X_train['eeg'][test]), y_train[test], verbose=0)\n",
    "    print(f'Score for fold  {fold_no}: {qat_model.metrics_names[0]} of {scores[0]}; {qat_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    accuracy_per_fold_2.append(scores[1] *100)\n",
    "    loss_per_fold_2.append(scores[0])\n",
    "          \n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Score per fold \")\n",
    "\n",
    "for i in range(0, len(accuracy_per_fold_2)):\n",
    "    print('-----------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold_2[i]} - Accuracy: {accuracy_per_fold_2[i]}%')\n",
    "print('-----------------------------------------------')\n",
    "print('Average Metrics for all folds: ')\n",
    "print(f'> Accuracy: {np.mean(accuracy_per_fold_2)} (+- {np.std(accuracy_per_fold_2)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold_2)}')\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6434576",
   "metadata": {},
   "source": [
    "Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='hybrid_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461978ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hybrid_net(input_size, eeg_input, intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf09b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_names = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        input_layer_names.append(layer.name)\n",
    "\n",
    "print(input_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (8, 40, 1)\n",
    "subject = 13\n",
    "\n",
    "#include path to the 32bit model example below\n",
    "emg_model_path = '/workspace/sEMG/BMIS_EMG_DATA/full_models'\n",
    "emg_subject = 'EMG-NET-' + str(subject) + '.h5'\n",
    "base_model_path = os.path.join(emg_model_path, emg_subject)\n",
    "base_model = tf.keras.models.load_model(base_model_path)\n",
    "\n",
    "\n",
    "\n",
    "eeg_input=base_model.inputs\n",
    "intermediate=[layer.output for layer in base_model.layers[1:5]]\n",
    "\n",
    "\n",
    "\n",
    "def hybrid_net(input_size, eeg_input, intermediate):\n",
    "    \n",
    "    \n",
    "    emg_input = tf.keras.Input(shape=input_size,  name=\"emg\")\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=input_size)(emg_input)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    emg_output = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    \n",
    "    \n",
    "    x = intermediate[-1]\n",
    "    eeg_output = x\n",
    "  \n",
    "    \n",
    "    concat = tf.keras.layers.concatenate([emg_output, eeg_output])\n",
    "    \n",
    "    down_stream_layer = tf.keras.layers.Flatten()(concat)\n",
    "    down_stream_layer = tf.keras.layers.Dropout(0.5)(down_stream_layer)\n",
    "    down_stream_layer = tf.keras.layers.Dense(100, activation='relu')(down_stream_layer)\n",
    "    down_stream_layer = tf.keras.layers.Dense(25, activation='relu')(down_stream_layer)\n",
    "    output = tf.keras.layers.Dense(7, activation='softmax')(down_stream_layer)\n",
    "    \n",
    "    hybrid_net = tf.keras.Model([emg_input, eeg_input], output, name='BMIS_Hybrid_Net')\n",
    "    \n",
    "    return hybrid_net\n",
    "\n",
    "\n",
    "\n",
    "def run_hybrid_net_experiment(start_subject=13, stop_subject=14, split_ratio=0.2, no_gesture=7, \n",
    "                              emg_fs=200, eeg_fs=250, notch_freq=60.0, quality_factor=30.0, \n",
    "                              eeg_fc=10.0, eeg_fh=35.0, emg_fc=10.0, emg_fh=99.0,order=5, window_time=200,\n",
    "                              overlap=60, no_channel=8, opt='adam', ls='sparse_categorical_crossentropy', \n",
    "                              mtr='accuracy', n_batches=16, n_epochs=1):\n",
    "    \n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        'Subject': [0],\n",
    "        'Validation_result':[0.0],\n",
    "        'qat_Validation_result':[0.0],\n",
    "        'Test_result_32_bit':[0.0],\n",
    "        'Test_result_8_bit_ptq':[0.0],\n",
    "        'Test_result_8_bit_qat':[0.0],\n",
    "        \n",
    "        'precision_full':[0.0],\n",
    "        'recall_full':[0.0],\n",
    "        'f1_score_full':[0.0],\n",
    "\n",
    "        'precision_ptq':[0.0],\n",
    "        'recall_ptq':[0.0],\n",
    "        'f1_score_ptq':[0.0],\n",
    "        \n",
    "        'precision_qat':[0.0],\n",
    "        'recall_qat':[0.0],\n",
    "        'f1_score_qat':[0.0]\n",
    "        })\n",
    "    \n",
    "    \n",
    "    emg_data, eeg_data, label = get_data_subject_specific(start_subject, no_gesture, emg_fs, eeg_fs,\n",
    "                                                      notch_freq, quality_factor, emg_fc, emg_fh, \n",
    "                                                      eeg_fc, eeg_fh, order,\n",
    "                                                      window_time, overlap, no_channel)\n",
    "\n",
    "    #print(f'Total EMG data is {emg_data.shape} EEG data is {eeg_data.shape} Label {label.shape}')\n",
    "    \n",
    "    \n",
    "    # EMG data split check this well\n",
    "    X_emg_train, y_train, X_emg_test, y_test = spilt_data(emg_data, label, ratio=split_ratio)\n",
    "    # EEG data split\n",
    "    X_eeg_train, _, X_eeg_test, _ = spilt_data(eeg_data, label, ratio=split_ratio)\n",
    "    \n",
    "    #X_eeg_train = X_eeg_train[:len(X_emg_train)]\n",
    "    #X_eeg_test = X_eeg_train[:len(X_emg_test)]\n",
    "    \n",
    "    \n",
    "    # Downsampling EEG\n",
    "    X_eeg_train = downsample_data(data=X_eeg_train, nfs=emg_fs, window_time=window_time)\n",
    "    X_eeg_test = downsample_data(data=X_eeg_test, nfs=emg_fs, window_time=window_time)\n",
    "    \n",
    "    \n",
    "    # Expanding the input feature shape for EMG\n",
    "    X_emg_train = np.expand_dims(X_emg_train, axis=3)\n",
    "    X_emg_test = np.expand_dims(X_emg_test, axis=3)\n",
    "    \n",
    "    # Expanding the input feature shape for EEG\n",
    "    X_eeg_train = np.expand_dims(X_eeg_train, axis=3)\n",
    "    X_eeg_test = np.expand_dims(X_eeg_test, axis=3)\n",
    "    input_size = X_emg_train.shape[1:]\n",
    "    \n",
    "    X_train = {'emg':X_emg_train, 'eeg':X_eeg_train}\n",
    "    X_test = {'emg':X_emg_test, 'eeg':X_eeg_test}\n",
    "    \n",
    "    for subject in range(start_subject, (stop_subject+1)):\n",
    "        \n",
    "        fold_no = 1\n",
    "        num_folds = 3\n",
    "        accuracy_per_fold = []\n",
    "        loss_per_fold = []\n",
    "        qat_accuracy_per_fold = []\n",
    "        qat_loss_per_fold = []\n",
    "        kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "        input_layer_names = []\n",
    "        \n",
    "        \n",
    "        emg_model_path = '/workspace/sEMG/BMIS_EMG_DATA/full_models'\n",
    "        emg_subject = 'EMG-NET-' + str(subject) + '.h5'\n",
    "        base_model_path = os.path.join(emg_model_path, emg_subject)\n",
    "        base_model = tf.keras.models.load_model(base_model_path)\n",
    "\n",
    "\n",
    "\n",
    "        eeg_input=base_model.inputs\n",
    "        intermediate=[layer.output for layer in base_model.layers[1:5]]\n",
    "        \n",
    "        \n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        print(f'Training and Evaluation for subject {subject}')\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        \n",
    "        \n",
    "            \n",
    "        emg_data, eeg_data, label = get_data_subject_specific(subject, no_gesture, emg_fs, eeg_fs,\n",
    "                                                          notch_freq, quality_factor, emg_fc, emg_fh, \n",
    "                                                          eeg_fc, eeg_fh, order,\n",
    "                                                          window_time, overlap, no_channel)\n",
    "\n",
    "        #print(f'Total EMG data is {emg_data.shape} EEG data is {eeg_data.shape} Label {label.shape}')\n",
    "\n",
    "\n",
    "        # EMG data split check this well\n",
    "        X_emg_train, y_train, X_emg_test, y_test = spilt_data(emg_data, label, ratio=split_ratio)\n",
    "        # EEG data split\n",
    "        X_eeg_train, _, X_eeg_test, _ = spilt_data(eeg_data, label, ratio=split_ratio)\n",
    "\n",
    "        #X_eeg_train = X_eeg_train[:len(X_emg_train)]\n",
    "        #X_eeg_test = X_eeg_train[:len(X_emg_test)]\n",
    "\n",
    "\n",
    "        # Downsampling EEG\n",
    "        X_eeg_train = downsample_data(data=X_eeg_train, nfs=emg_fs, window_time=window_time)\n",
    "        X_eeg_test = downsample_data(data=X_eeg_test, nfs=emg_fs, window_time=window_time)\n",
    "\n",
    "\n",
    "        # Expanding the input feature shape for EMG\n",
    "        X_emg_train = np.expand_dims(X_emg_train, axis=3)\n",
    "        X_emg_test = np.expand_dims(X_emg_test, axis=3)\n",
    "\n",
    "        # Expanding the input feature shape for EEG\n",
    "        X_eeg_train = np.expand_dims(X_eeg_train, axis=3)\n",
    "        X_eeg_test = np.expand_dims(X_eeg_test, axis=3)\n",
    "        input_size = X_emg_train.shape[1:]\n",
    "        \n",
    "        model_check_name = hybrid_net(input_size, eeg_input, intermediate)\n",
    "        for layer in model_check_name.layers:\n",
    "            if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "                input_layer_names.append(layer.name)\n",
    "        \n",
    "        \n",
    "        X_train = {'emg':X_emg_train, 'eeg':X_eeg_train}\n",
    "        X_test = {'emg':X_emg_test, input_layer_names[0]:X_eeg_test}\n",
    "        \n",
    "        \n",
    "        \n",
    " \n",
    "        \n",
    "        calibration_dataset = {'emg':X_emg_train[:1000], input_layer_names[0]:X_eeg_train[:1000]} # Calibration data needed to quantize the model\n",
    "        print(f'Input shape to the Hybrid-Net Model is: {input_size}')\n",
    "        \n",
    "        \n",
    "        for train, test in kfold.split(X_train['emg'], y_train):\n",
    "    \n",
    "            model = hybrid_net(input_size, eeg_input, intermediate)\n",
    "            model.compile(optimizer=opt, loss=ls, metrics=mtr)\n",
    "            checkpoint_path = os.path.join('../checkpoint/full', str(subject))\n",
    "\n",
    "            if not os.path.exists(checkpoint_path):\n",
    "                os.makedirs(checkpoint_path)\n",
    "\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n",
    "            checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = checkpoint_path, save_best_only=True,\n",
    "                                        monitor='accuracy', vebrose=1)\n",
    "    \n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Training Unquantized Model for fold {fold_no} -------')\n",
    "    \n",
    "            history = model.fit((X_train['emg'][train],X_train['eeg'][train]), y_train[train], \n",
    "                                callbacks=[early_stop, checkpoint_callback], \n",
    "                                batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "        \n",
    "    \n",
    "            scores = model.evaluate((X_train['emg'][test],X_train['eeg'][test]), y_train[test], verbose=0)\n",
    "            print(f'Score for fold  {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "            accuracy_per_fold.append(scores[1] *100)\n",
    "            loss_per_fold.append(scores[0])\n",
    "          \n",
    "            \n",
    "            \n",
    "            print('######################################################')\n",
    "            print('Quantization Aware Training')\n",
    "            \n",
    "            qat_checkpoint_path = os.path.join('../checkpoint/qat', str(subject))\n",
    "\n",
    "            if not os.path.exists(qat_checkpoint_path):\n",
    "                os.makedirs(qat_checkpoint_path)\n",
    "     \n",
    "\n",
    "            qat_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath = qat_checkpoint_path, save_best_only=True, monitor='accuracy', vebrose=1)\n",
    "            \n",
    "            qat_model = hybrid_net(input_size, eeg_input, intermediate)\n",
    "            quantizer = vitis_quantize.VitisQuantizer(qat_model, quantize_strategy='8bit_tqt')\n",
    "            qat_model_set = quantizer.get_qat_model(init_quant=True, calib_dataset=calibration_dataset)\n",
    "\n",
    "            qat_model.compile(optimizer= opt, loss=ls, metrics=mtr)\n",
    "\n",
    "            print('---------------------------------------------------')\n",
    "            print(f'Quantization Aware Training for fold {fold_no} -------')\n",
    "\n",
    "            qat_history = qat_model.fit((X_train['emg'][train],X_train['eeg'][train]), y_train[train], \n",
    "                                        callbacks=[early_stop, qat_checkpoint_callback], \n",
    "                                        batch_size=n_batches, epochs= n_epochs, verbose=1)\n",
    "\n",
    "            qat_scores = qat_model.evaluate((X_train['emg'][test],X_train['eeg'][test]), y_train[test], verbose=0)\n",
    "            print(f'QAT Score for fold  {fold_no}: {qat_model.metrics_names[0]} of {qat_scores[0]}; {qat_model.metrics_names[1]} of {qat_scores[1]*100}%')\n",
    "            qat_accuracy_per_fold.append(qat_scores[1] *100)\n",
    "            qat_loss_per_fold.append(scores[0])\n",
    "\n",
    "            fold_no = fold_no + 1     \n",
    "\n",
    "        \n",
    "        print(\"Average Full Bit Validation Score per fold \")\n",
    "\n",
    "        for i in range(0, len(accuracy_per_fold)):\n",
    "            print('-----------------------------------------------')\n",
    "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {accuracy_per_fold[i]}%')\n",
    "        print('-----------------------------------------------')\n",
    "        print('Average Metrics for all folds: ')\n",
    "        print(f'> Accuracy: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
    "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "        print('-----------------------------------------------')\n",
    "        print('############################################################')\n",
    "        print(f'Training Ended for subject {subject}')\n",
    "        print('############################################################')\n",
    "        \n",
    "        validation_result = np.mean(accuracy_per_fold)\n",
    "        qat_validation_result = np.mean(qat_accuracy_per_fold)\n",
    "        \n",
    "        ######### Load the best model from checkpoint. ################\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "        \n",
    "        ############# Evaluating 32-bit Model ##########################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating Unquantized Model')\n",
    "        print('############################################################')\n",
    "        uqt_test_loss, uqt_test_accuracy = model.evaluate(X_test, y_test)\n",
    "        full_test_accuracy = uqt_test_accuracy * 100\n",
    "        print(f'Accuracy of the Unquantized_model {full_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        y_predict = model.predict(X_test)\n",
    "        y_predict = np.argmax(y_predict, axis=-1)\n",
    "   \n",
    "        precision = precision_score(y_test, y_predict, average='weighted')\n",
    "        recall = recall_score(y_test, y_predict, average='weighted')\n",
    "        f1_score_full = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'Precision of the Unquantized model {precision}')\n",
    "        print(f'Recall of the Unquantized model {recall}')\n",
    "        print(f'F1_score of the Unquantized model {f1_score_full}')\n",
    "    \n",
    "        \n",
    "        ############ Save the full model as .h5. This will be used for quantization #####\n",
    "        saved_model = '../full_models/Hybrid-Net-' + str(subject) + '.h5'\n",
    "        model.save(saved_model)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ############### Post-Training Quantization ########################\n",
    "        saved_float32_model = tf.keras.models.load_model(saved_model)\n",
    "        ptq_quantizer = vitis_quantize.VitisQuantizer(saved_float32_model)\n",
    "        ptq_model = ptq_quantizer.quantize_model(calib_dataset=calibration_dataset)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting PTQ Model #######################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating PTQ Model')\n",
    "        print('############################################################')\n",
    "\n",
    "        ptq_model.compile(loss=ls, metrics=mtr)\n",
    "        ptq_loss, ptq_test_accuracy = ptq_model.evaluate(X_test, y_test)\n",
    "        ptq_test_accuracy = ptq_test_accuracy * 100\n",
    "        print(f'Accuracy of the PTQ model {ptq_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "            \n",
    "        ptq_y_predict = ptq_model.predict(X_test)\n",
    "        ptq_y_predict = np.argmax(ptq_y_predict, axis=-1)\n",
    "        ptq_precision = precision_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_recall = recall_score(y_test, ptq_y_predict, average='weighted')\n",
    "        ptq_f1_score = 2 * (ptq_precision * ptq_recall) / (ptq_precision + ptq_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the PTQ model {ptq_precision}')\n",
    "        print(f'Recall of the PTQ model {ptq_recall}')\n",
    "        print(f'F1_score of the PTQ model {ptq_f1_score}')\n",
    "\n",
    "        # Saving PTQ model; Can be complied for depolyment #######  \n",
    "        ptq_quantized_model = '../ptq_models/ptq-Hybrid-Net-' + str(subject) + '.h5'\n",
    "        ptq_model.save(ptq_quantized_model)\n",
    "        \n",
    "        \n",
    "        ############# Evalauting QAT Model ###################################\n",
    "        \n",
    "        ## Load Best QAT Model\n",
    "        qat_model = tf.keras.models.load_model(qat_checkpoint_path)\n",
    "        \n",
    "        ## ######### Evaluate QAT Model###############################################\n",
    "        print('############################################################')\n",
    "        print(f'Evaluating QAT Model')\n",
    "        print('############################################################')\n",
    "        \n",
    "        qat_test_loss, qat_test_accuracy = qat_model.evaluate(X_test, y_test)\n",
    "        qat_test_accuracy = qat_test_accuracy * 100\n",
    "        print(f'Accuracy of the QAT model {qat_test_accuracy}%')\n",
    "        \n",
    "        \n",
    "        qat_y_predict = qat_model.predict(X_test)\n",
    "        qat_y_predict = np.argmax(qat_y_predict, axis=-1)\n",
    "        qat_precision = precision_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_recall = recall_score(y_test, qat_y_predict, average='weighted')\n",
    "        qat_f1_score = 2 * (qat_precision * qat_recall) / (qat_precision + qat_recall)\n",
    "        \n",
    "        \n",
    "        print(f'Precision of the QAT model {qat_precision}')\n",
    "        print(f'Recall of the QAT model {qat_recall}')\n",
    "        print(f'F1_score of the QAT model {qat_f1_score}')\n",
    "        \n",
    "        # Saving QAT model; Can be complied for depolyment #######  \n",
    "        qat_quantized_model = '../qat_models/qat-Hybrid-Net-' + str(subject) + '.h5'\n",
    "        qat_model.save(qat_quantized_model)\n",
    "        \n",
    "        \n",
    "        result.at[subject-1, 'Subject'] = subject\n",
    "        result.at[subject-1, 'Validation_result'] = validation_result\n",
    "        result.at[subject-1, 'qat_Validation_result'] = qat_validation_result\n",
    "        result.at[subject-1, 'Test_result_32_bit'] = full_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_ptq'] = ptq_test_accuracy\n",
    "        result.at[subject-1, 'Test_result_8_bit_qat'] = qat_test_accuracy\n",
    "        \n",
    "        result.at[subject-1, 'precision_full'] = precision \n",
    "        result.at[subject-1, 'recall_full'] = recall\n",
    "        result.at[subject-1, 'f1_score_full'] = f1_score_full\n",
    "   \n",
    "        result.at[subject-1, 'precision_ptq'] = ptq_precision \n",
    "        result.at[subject-1, 'recall_ptq'] = ptq_recall\n",
    "        result.at[subject-1, 'f1_score_ptq'] = ptq_f1_score\n",
    "        \n",
    "        result.at[subject-1, 'precision_qat'] = qat_precision \n",
    "        result.at[subject-1, 'recall_qat'] = qat_recall\n",
    "        result.at[subject-1, 'f1_score_qat'] = qat_f1_score\n",
    "\n",
    "        save_path = str(start_subject)+'_to_'+str(stop_subject)+'_new_Hybrid-Net.csv'\n",
    "        save_path = os.path.join('../results', save_path)\n",
    "        result.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11464bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_hybrid_net_experiment(start_subject=1, stop_subject=33, split_ratio=0.1, no_gesture=7, \n",
    "                          emg_fs=200, eeg_fs=250, notch_freq=60.0, quality_factor=30.0, \n",
    "                          eeg_fc=10.0, eeg_fh=35.0, emg_fc=10.0, emg_fh=99.0,order=5, window_time=200,\n",
    "                          overlap=60, no_channel=8, opt='adam', ls='sparse_categorical_crossentropy', \n",
    "                          mtr='accuracy', n_batches=16, n_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
